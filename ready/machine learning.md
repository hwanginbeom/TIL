
	1. 머신러닝 / 딥러닝 지식

		1.
배경지식

			1.
머신러닝 이란 ? 애플리케이션을 수정하지 않고 데이터를 통해 패턴을 학습하여 결과를 예측하는 알고리즘 기법 / 데이터를 기반으로 숨겨진 패턴을 인지
			2.
머신러닝의 분류

				1.
지도 학습

					1.
분류
					2.
회귀
					3.
추천시스템
					4.
시각/음성, 감지/인지
					5.
텍스트분석, NLP
				2.
비지도 학습

					1.
군집화(클러스터링)
					2.
차원축소
					3.
강화학습
			3.
알고리즘 < 데이터 -> 둘다 중요하지만 데이터가 더 중요하다  - 가비지 인 가비지 아웃
			4.
파이썬의 장점

				1.
높은 개발 생산성
				2.
오픈 소스계열의 지원을 받으며 많은 라이브러리가 있다
				3.
인터프리터 언어의 특징 - 느리지만 뛰어난 확장성, 유연성, 호환성 -> 서버, 네트워크, 시스템, IOT
				4.
머신러닝 애플리케이션과 결합해 애플리케이션 개발이 가능하다.
				5.
기업환경으로 확산이 가능하다.
				6.
텐서플로, 케라스,파이토치등이 가능하다
			5.
행렬/선형대수/통계 패키지 - 넘파이
			6.
데이터 핸들링 - 판다스

				1.
iloc 위치기반
				2.
loc 명칭기반
				3.
sort_value(by=['컬럼'], ascending=False )  / .sort()
				4.
groupby('컬럼명').어쩌고
				5.
agg(['컬럼명','컬럼명']) - 여러 컬럼을 지정
				6.
.isna() - 널값 확인
				7.
fillna('???') - 널값 대체
				8.
apply lambda - squares = map(lambda x : x **2, a) / .apply(lambda x : len(x)) - 칼럼에 일괄적으로 데이터 가공
			7.
넘파이
		2.
사이킷런

			1.
train_test_split(data, target, testsize=0.3, random_state=777)
			2.
교차검증 - 과적합(모델이 현재 학습 데이터에만 과도학게 최적화되어 실제 예측을 다른 데이터로 수행하는 경우 성능이 떨어지는 경우)

				1.
k-폴드 - k개의 데이터 폴드 세트를 만들어 수행
				2.
stratified k 폴드 - 불균형한 분포도를 가진 레이블을 위한 k폴드 방식으로 일정이상의 레이블을 유지
				3.
loocv - 데이터가 적을때 사용하는 것으로 레이블을 하나로 나머지를 학습으로 사용하는 방법
				4.
hold out - 내가 임의로 데이터 셋을 쪼개는 것
				5.
cross_val_score() - 모델 + 교차검증 + 성능평가를 한번에 하는 방법
			3.
하이퍼 파리미터

				1.
gridSearchCV - 교차검증과 최적 하이퍼 파라미터 튜닝. 구간 내에 몇가지 값 넣고 찾는 것
				2.
Manual Search - 직접 넣어보는거
				3.
Random Search - 구간내 값을 랜덤 샘플링을 통해 선정
				4.
Bayesian optimization - 알려지지 않는 목적함수를 최대(최소)로하는 최적해 기법

					1.
surrogate 모델 - 입출력 특성을 실제모형과 유사하게 만드는 것을 목적 / 추상화된  모델을 통해서 입력과 출력의 관계를 설명 (가우시안 프로세스 많이씀)
					2.
Acquistion(어큐션) 함수 - 확률적 추정 결과를 바탕으로 다음 입력값 후보를 추천


	1. 평가

		1.
정확도(Accuracy)

			1.
실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표
			2.
직관적이긴 하지만 모델의 성능을 왜곡 할 수 있다.(불균형한 레이블 세트에서는 사용하면 안된다.)
			3.
(TN + TP) / (TN + FP + FN + TP)
		2.
오차행렬

			1.
TN - 부정이라고해서 맞은경우
			2.
TP - 긍정이라고 해서 맞은경우
			3.
FN - 부정이라고해서 틀린 경우
			4.
FP - 긍정이라고 해서 틀린 경우
		3.
정밀도와 재현율

			1.
정밀도(Precision) - 긍정(양성 예측도)으로 예측한 것들로 비교  (TP / (FP + TP))   ex)스팸
			2.
재현율(Recall) - TP / (FN + TP) - 부정이라고 예측한 것들로 비교  ex)암
			3.
정밀도 / 재현율 트레이드 오프

				1.
임곗값 조정을 통해 한쪽의 수치를 높일 수 있다.
				2.
상호보완으로 써야 한다.(적절하게 써야함)
		4.
F1 스코어

			1.
정밀도와 재현율을 결합한 지표(한쪽으로 치우치지 않을때 높은 값을 가진다.)
		5.
ROC 곡선과 AUC - (이진 분류의 예측 성능 측정에서 중요하게 사용 되는 지표)

			1.
ROC 곡선 - 수신자 판단 곡선, FPR(특이도)이 변할 때 TPR(민감도)이 어떻게 변하는 지를 타나내는 곡선
			2.
민감도(환자를 환자로)와 특이도(정상인을 정산인으로)
			3.
TPR -1 / FPR -0(1-TPR)
			4.
ROC 곡선이 1에서 가까워질수록 성능이 좋다.
			5.
AUC는 면적



	1. 분류

		1.
분류란

			1.
답(레이블)이 있는 데이터가 주어진 상태에서 학습하는 머신러닝 방식
		2.
결정트리

			1.
데이터에 있는 규칙을 학습을 통해 찾아내 트리 기반의 분류 규칙 생성(if/else)
			2.
많은 규칙 - 과적합으로 간다. 깊어질 수록 과적합일 가능성이 높다
			3.
엔트로피 - 데이터 집합의 혼잡도 / 다른 값이 섞여있으면 엔트로피가 높다.
			4.
특징

				1.
장점 - 쉽고 직관적 ,트리가 룰이 명확해 어떻게 구성되는지를 알수 있다.
				2.
단점 - 과적합으로 정확도가 떨어진다.
			5.
파라미터

				1.
노드를 분할하기 위한 최소 샘플 데이터수
				2.
노드가 되기위한 최소한의 샘플 데이터 수
				3.
최대 피처개수
				4.
트리 깊이
				5.
노드의 최대 개수
		3.
앙상블학습

			1.
여러 개의 분류기를 생성하고 그 예측을 결합함으로써 성능을 올리는 기법
			2.
보팅 - 여러개의 분류기가 투표를 통해 최종 예측 결과를 결정

				1.
하드 보팅 - 다수결 원칙(다수의 분류기가 결정한 예측값으로 선정)
				2.
소프트 보팅 - 분류기들의 레이블 값 결정 확률을 모두 더하고 이를 평균해서 이들 중 확률이 가장 높은 레이블 값을 최종값으로 선택
			3.
배깅 - 각각의 분류기가 모두 같은 알고리즘이지만, 데이터 샘플링을 서로 다르게 하여 결과물 집계.(랜덤 포레스트)
			4.
부스팅 - 여러개의 분류리가 순차적으로 학습을 수행하되, 틀린 데이터에 대해 가중치를 부여하면서 학습을 하는 방식
			5.
스태킹 - 여러 가지 다른 모델의 예측 결괏값을 다시 학습데이터로 만들어 다른 모델로 재학습 시켜 결과를 예측하는 방법
		4.
랜덤포레스트

			1.
쉽고 직관적이며 빠른 수행 속도
			2.
트리기반의 단점은 하이퍼 파라미터가 너무 많고 시간이 오래 걸린다.
		5.
GBM

			1.
약한 학습기를 순차적으로 학습 예측하면서 가중치를 부여해 학습하는 방식
			2.
adaboost 비슷함
			3.
gbm은 경사하강법을 쓴다.
		6.
XGBoost

			1.
gbm 기반
			2.
장점

				1.
빠른 수행 시간
				2.
TreePruning(이득이 없는 분할을 가지치기 할 수 있다.) - 과적합 규제
				3.
자체 내장된 교차 검증 / 성능평가 / 피처 중요도
				4.
결손값 처리
				5.
병렬 CPU 환경에서 병렬 학습 가능
			3.
c/c++로 구성
			4.
파이썬 래퍼 모듈 / 사이킷런 래퍼 모듈이 있음
		7.
LightGBM

			1.
장점

				1.
메모리 사용량이 더 적다
				2.
XGB보다 빠르다.
				3.
카테고리형 피처의 자동 변환과 최적 분할
			2.
단점- 적은 데이터에서 과적합에 취약
			3.
리프 중심 트리 분할 방식 사용 leaf wise() - 최대 손실 값을 가지는 리프노드를 분할  / 일반적으로 균형 트리 분할(Level Wise) - 오버피팅에 강함 but 시간이 오래걸림
		8.
스태킹 앙상블

			1.
개별 결과 데이터 세트를 최종적인 메타 데이터 세트로 만든다.
